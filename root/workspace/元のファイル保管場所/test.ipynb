{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c460f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 01:33:51.608398: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n",
      "Physical GPUs: 2, Logical GPUs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 01:33:54.930357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11287 MB memory:  -> device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1\n",
      "2025-10-16 01:33:54.931672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 11549 MB memory:  -> device: 1, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (0, 1)                    2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2 (8.00 Byte)\n",
      "Trainable params: 2 (8.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 01:33:55.736580: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5300a61ab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-16 01:33:55.736616: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2025-10-16 01:33:55.736623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA TITAN X (Pascal), Compute Capability 6.1\n",
      "2025-10-16 01:33:55.812739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73/625 [==>...........................] - ETA: 1s - loss: 0.1318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 01:33:56.111618: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 2ms/step - loss: 0.0238\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 5.1882e-06\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.2134e-09\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 3.6031e-12\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 3.2314e-12\n",
      "ground truth: 0.8, 0.2\n",
      "estimated:  0.8000031 0.20000002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(\"Physical GPUs: {}, Logical GPUs: {}\".format(len(gpus), len(logical_gpus)))\n",
    "else:\n",
    "    print(\"CPU only\")\n",
    "\n",
    "x = np.arange(-1, 1, 0.0001)\n",
    "y = 0.8 * x + 0.2\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, activation=None)])\n",
    "model.compile(\"sgd\", \"mse\")\n",
    "model.build(input_shape=(0,1))\n",
    "model.summary()\n",
    "model.fit(x, y, epochs=5)\n",
    "\n",
    "print(\"ground truth: 0.8, 0.2\")\n",
    "print(\"estimated: \", model.variables[0][0,0].numpy(), model.variables[1][0].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7df92e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 08:12:52.671010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 115 MB memory:  -> device: 0, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1\n",
      "2025-09-19 08:12:52.671480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:1 with 11413 MB memory:  -> device: 1, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "706c834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42817298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7335803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. データ準備 (前回と同じ) ---\n",
    "df = pd.read_excel(\"./深層学習.xlsx\")\n",
    "X = df[['left_x', 'left_y', 'right_x', 'right_y', 'left_pupil', 'right_pupil']]\n",
    "y = df[\"is_correct\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07858abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- --------------------\n",
      "absl-py                      1.4.0\n",
      "asttokens                    3.0.0\n",
      "astunparse                   1.6.3\n",
      "backcall                     0.2.0\n",
      "cachetools                   5.3.1\n",
      "certifi                      2019.11.28\n",
      "chardet                      3.0.4\n",
      "comm                         0.2.3\n",
      "contourpy                    1.1.1\n",
      "cycler                       0.12.1\n",
      "dbus-python                  1.2.16\n",
      "debugpy                      1.8.17\n",
      "decorator                    5.2.1\n",
      "et_xmlfile                   2.0.0\n",
      "executing                    2.2.1\n",
      "filelock                     3.16.1\n",
      "flatbuffers                  23.5.26\n",
      "fonttools                    4.57.0\n",
      "fsspec                       2025.3.0\n",
      "gast                         0.4.0\n",
      "google-auth                  2.21.0\n",
      "google-auth-oauthlib         1.0.0\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.56.0\n",
      "h5py                         3.9.0\n",
      "idna                         2.8\n",
      "importlib-metadata           6.7.0\n",
      "importlib_resources          6.4.5\n",
      "ipykernel                    6.29.5\n",
      "ipython                      8.12.3\n",
      "jedi                         0.19.2\n",
      "Jinja2                       3.1.6\n",
      "joblib                       1.4.2\n",
      "jupyter_client               8.6.3\n",
      "jupyter_core                 5.8.1\n",
      "keras                        2.13.1\n",
      "kiwisolver                   1.4.7\n",
      "libclang                     16.0.0\n",
      "Markdown                     3.4.3\n",
      "MarkupSafe                   2.1.3\n",
      "matplotlib                   3.7.5\n",
      "matplotlib-inline            0.1.7\n",
      "mpmath                       1.3.0\n",
      "nest-asyncio                 1.6.0\n",
      "networkx                     3.1\n",
      "numpy                        1.24.3\n",
      "nvidia-cublas-cu12           12.1.3.1\n",
      "nvidia-cuda-cupti-cu12       12.1.105\n",
      "nvidia-cuda-nvrtc-cu12       12.1.105\n",
      "nvidia-cuda-runtime-cu12     12.1.105\n",
      "nvidia-cudnn-cu12            9.1.0.70\n",
      "nvidia-cufft-cu12            11.0.2.54\n",
      "nvidia-curand-cu12           10.3.2.106\n",
      "nvidia-cusolver-cu12         11.4.5.107\n",
      "nvidia-cusparse-cu12         12.1.0.106\n",
      "nvidia-nccl-cu12             2.20.5\n",
      "nvidia-nvjitlink-cu12        12.9.86\n",
      "nvidia-nvtx-cu12             12.1.105\n",
      "oauthlib                     3.2.2\n",
      "openpyxl                     3.1.5\n",
      "opt-einsum                   3.3.0\n",
      "packaging                    23.1\n",
      "pandas                       2.0.3\n",
      "parso                        0.8.5\n",
      "pexpect                      4.9.0\n",
      "pickleshare                  0.7.5\n",
      "pillow                       10.4.0\n",
      "pip                          25.0.1\n",
      "platformdirs                 4.3.6\n",
      "prompt_toolkit               3.0.52\n",
      "protobuf                     4.23.3\n",
      "psutil                       7.1.0\n",
      "ptyprocess                   0.7.0\n",
      "pure_eval                    0.2.3\n",
      "pyasn1                       0.5.0\n",
      "pyasn1-modules               0.3.0\n",
      "Pygments                     2.19.2\n",
      "PyGObject                    3.36.0\n",
      "pyparsing                    3.1.4\n",
      "python-apt                   2.0.1+ubuntu0.20.4.1\n",
      "python-dateutil              2.9.0.post0\n",
      "pytz                         2025.2\n",
      "pyzmq                        27.1.0\n",
      "requests                     2.22.0\n",
      "requests-oauthlib            1.3.1\n",
      "requests-unixsocket          0.2.0\n",
      "rsa                          4.9\n",
      "scikit-learn                 1.3.2\n",
      "scipy                        1.10.1\n",
      "seaborn                      0.13.2\n",
      "setuptools                   68.0.0\n",
      "six                          1.14.0\n",
      "stack-data                   0.6.3\n",
      "sympy                        1.13.3\n",
      "tensorboard                  2.13.0\n",
      "tensorboard-data-server      0.7.1\n",
      "tensorflow                   2.13.0\n",
      "tensorflow-estimator         2.13.0\n",
      "tensorflow-io-gcs-filesystem 0.32.0\n",
      "termcolor                    2.3.0\n",
      "threadpoolctl                3.5.0\n",
      "torch                        2.4.1\n",
      "tornado                      6.4.2\n",
      "traitlets                    5.14.3\n",
      "triton                       3.0.0\n",
      "typing_extensions            4.13.2\n",
      "tzdata                       2025.2\n",
      "urllib3                      1.25.8\n",
      "wcwidth                      0.2.13\n",
      "Werkzeug                     2.3.6\n",
      "wheel                        0.40.0\n",
      "wrapt                        1.15.0\n",
      "zipp                         3.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "247ce69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 6)]               0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 6, 1)              0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 6, 32)             64        \n",
      "                                                                 \n",
      " transformer_block_1 (Trans  ((None, 6, 32),           19040     \n",
      " formerBlock)                 (None, 4, 6, 6))                   \n",
      "                                                                 \n",
      " global_average_pooling1d_1  (None, 32)                0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 20)                660       \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " classification_output (Den  (None, 1)                 21        \n",
      " se)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19785 (77.29 KB)\n",
      "Trainable params: 19785 (77.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'pandas.core.series.Series'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 96\u001b[0m\n\u001b[1;32m     92\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# --- 3. 学習 (前回と同じ) ---\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 学習過程の表示をオフに\u001b[39;49;00m\n\u001b[1;32m    102\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m学習が完了しました。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# --- 4. アテンションの可視化 ---\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# テストデータから1つサンプルを選んで予測\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/engine/data_adapter.py:1766\u001b[0m, in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split)\u001b[0m\n\u001b[1;32m   1764\u001b[0m unsplitable \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtype\u001b[39m(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_arrays \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _can_split(t)]\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsplitable:\n\u001b[0;32m-> 1766\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1767\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_split` is only supported for Tensors or NumPy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1768\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrays, found following types in the input: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(unsplitable)\n\u001b[1;32m   1769\u001b[0m     )\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_arrays):\n\u001b[1;32m   1772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arrays, arrays\n",
      "\u001b[0;31mValueError\u001b[0m: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'pandas.core.series.Series'>]"
     ]
    }
   ],
   "source": [
    "# X, y = make_classification(\n",
    "#     n_samples=1000,\n",
    "#     n_features=10,\n",
    "#     n_informative=4,\n",
    "#     n_redundant=2,\n",
    "#     n_classes=2,\n",
    "#     random_state=42\n",
    "# )\n",
    "# feature_names = [f'feature_{i}' for i in range(10)]\n",
    "# X = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# --- 2. モデル構築 (アテンション可視化対応) ---\n",
    "\n",
    "# Transformerブロックのcallメソッドを変更し、アテンションスコアを返せるようにする\n",
    "# ...existing code...\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=None, return_attention_scores=False):  # ← ここを修正\n",
    "        attention_output, attention_scores = self.att(\n",
    "            inputs, inputs, return_attention_scores=True\n",
    "        )\n",
    "        attention_output = self.dropout1(attention_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attention_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        output = self.layernorm2(out1 + ffn_output)\n",
    "        if return_attention_scores:\n",
    "            return output, attention_scores\n",
    "        return output\n",
    "# ...existing code...\n",
    "\n",
    "# モデル定義関数を修正\n",
    "def create_visualizable_transformer(num_features, embed_dim=32, num_heads=4, ff_dim=32):\n",
    "    inputs = tf.keras.layers.Input(shape=(num_features,))\n",
    "    \n",
    "    # 1. 各特徴量を独立したトークンとして扱うため、次元を追加\n",
    "    # (Batch, Features) -> (Batch, Features, 1)\n",
    "    x = tf.keras.layers.Reshape((num_features, 1))(inputs)\n",
    "\n",
    "    # 2. 各特徴量を個別に埋め込みベクトルに変換\n",
    "    # Conv1Dは各タイムステップ(今回は特徴量)に同じカーネルを適用するため、\n",
    "    # TimeDistributed(Dense) と同様の役割を果たし、効率的\n",
    "    x = tf.keras.layers.Conv1D(embed_dim, kernel_size=1, activation='relu')(x)\n",
    "\n",
    "    # 3. Transformerブロックを適用し、アテンションスコアも受け取る\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    x, attention_scores = transformer_block(x, return_attention_scores=True)\n",
    "    \n",
    "    # 4. 分類のための後処理\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.Dense(20, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"classification_output\")(x)\n",
    "\n",
    "    # 最終的な分類出力と、途中のアテンションスコアを両方出力するモデルを作成\n",
    "    model = tf.keras.Model(\n",
    "        inputs=inputs,\n",
    "        outputs=[outputs, attention_scores]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# モデルのインスタンスを作成\n",
    "model = create_visualizable_transformer(num_features=X_train.shape[1])\n",
    "\n",
    "# モデルのコンパイル (出力が2つあるため、lossも2つ指定)\n",
    "# アテンションスコアには損失は不要なので、Noneを指定\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=[\"binary_crossentropy\", None], # attention_scoresのlossは計算しない\n",
    "    metrics={\"classification_output\": \"accuracy\"}\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# --- 3. 学習 (前回と同じ) ---\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    verbose=0 # 学習過程の表示をオフに\n",
    ")\n",
    "print(\"学習が完了しました。\")\n",
    "\n",
    "\n",
    "# --- 4. アテンションの可視化 ---\n",
    "\n",
    "# テストデータから1つサンプルを選んで予測\n",
    "sample_index = 0\n",
    "sample_input = np.expand_dims(X_test[sample_index], axis=0)\n",
    "\n",
    "# 予測と同時にアテンションスコアを取得\n",
    "prediction, attention_scores = model.predict(sample_input)\n",
    "\n",
    "# アテンションスコアの整形\n",
    "# (Batch, Heads, Features, Features) -> (Heads, Features, Features)\n",
    "attention_scores = attention_scores[0]\n",
    "# ヘッド間で平均を取る\n",
    "attention_matrix = np.mean(attention_scores, axis=0)\n",
    "\n",
    "# ヒートマップで可視化\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(attention_matrix, xticklabels=feature_names, yticklabels=feature_names, annot=True, cmap='viridis')\n",
    "plt.title(f'Attention Matrix for Sample #{sample_index}')\n",
    "plt.xlabel('Key (attended to)')\n",
    "plt.ylabel('Query (attending from)')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nサンプル #{sample_index} の予測確率: {prediction[0][0]:.4f}\")\n",
    "print(f\"正解ラベル: {y_test[sample_index]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
